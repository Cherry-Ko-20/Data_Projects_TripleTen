{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment V3</b>\n",
    "\n",
    "Thank you for taking the time to improve the project! It is now accepted. Good luck on the next sprint!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Review**\n",
    "\n",
    "Hi, my name is Dmitry and I will be reviewing your project.\n",
    "  \n",
    "You can find my comments in colored markdown cells:\n",
    "  \n",
    "<div class=\"alert alert-success\">\n",
    "  If everything is done successfully.\n",
    "</div>\n",
    "  \n",
    "<div class=\"alert alert-warning\">\n",
    "  If I have some (optional) suggestions, or questions to think about, or general comments.\n",
    "</div>\n",
    "  \n",
    "<div class=\"alert alert-danger\">\n",
    "  If a section requires some corrections. Work can't be accepted with red comments.\n",
    "</div>\n",
    "  \n",
    "Please don't remove my comments, as it will make further review iterations much harder for me.\n",
    "  \n",
    "Feel free to reply to my comments or ask questions using the following template:\n",
    "  \n",
    "<div class=\"alert alert-info\">\n",
    "  For your comments and questions.\n",
    "</div>\n",
    "  \n",
    "First of all, thank you for turning in the project! You did a pretty good job overall, but there are a couple of problems that need to be fixed before the project is accepted. Let me know if you have questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Title: Customer Churn Prediction for Beta Bank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beta Bank, a prominent financial institution, has been facing a growing issue - customers leaving the bank over time. As a cost-effective strategy, Beta Bank has decided to prioritize retaining existing customers over acquiring new ones. In order to achieve this, the bank aims to predict which customers are likely to leave soon. To tackle this challenge, we have access to historical data on customer behavior and contract terminations.\n",
    "\n",
    "Project Objectives:\n",
    "\n",
    "Predict Customer Churn: Build a machine learning model that predicts whether a customer is likely to leave Beta Bank in the near future.\n",
    "\n",
    "Maximize F1 Score: Develop a model with the highest possible F1 score, aiming for a minimum F1 score of 0.59.\n",
    "\n",
    "AUC-ROC Evaluation: Measure the AUC-ROC (Area Under the Receiver Operating Characteristic) metric to assess the model's performance and compare it with the F1 score.\n",
    "\n",
    "Project Steps:\n",
    "\n",
    "Data Preparation: Download and preprocess the dataset, handling missing values, encoding categorical features, and scaling numeric attributes.\n",
    "\n",
    "Class Imbalance Analysis: Examine the balance of classes in the dataset and understand the severity of the class imbalance.\n",
    "\n",
    "Model Training without Balancing: Train initial models without addressing class imbalance and evaluate their performance.\n",
    "\n",
    "Improve Model Quality: Apply at least two techniques to fix class imbalance, such as upsampling, downsampling, or using class weights. Select the best model parameters through hyperparameter tuning.\n",
    "\n",
    "Model Training and Validation: Train different models on training and validation sets, comparing their F1 scores and AUC-ROC values.\n",
    "\n",
    "Select the Best Model: Choose the model with the highest F1 score as the best-performing model.\n",
    "\n",
    "Final Testing: Evaluate the selected model on the test set and report the F1 score and AUC-ROC score.\n",
    "\n",
    "By executing these steps, Beta Bank aims to identify customers at risk of churning and take proactive measures to retain them, ultimately improving customer retention and reducing costs associated with customer acquisition.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10.0</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "0             1    15634602   Hargrave          619    France  Female   42   \n",
       "1             2    15647311       Hill          608     Spain  Female   41   \n",
       "2             3    15619304       Onio          502    France  Female   42   \n",
       "3             4    15701354       Boni          699    France  Female   39   \n",
       "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
       "...         ...         ...        ...          ...       ...     ...  ...   \n",
       "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
       "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
       "9997       9998    15584532        Liu          709    France  Female   36   \n",
       "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0        2.0       0.00              1          1               1   \n",
       "1        1.0   83807.86              1          0               1   \n",
       "2        8.0  159660.80              3          1               0   \n",
       "3        1.0       0.00              2          0               0   \n",
       "4        2.0  125510.82              1          1               1   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "9995     5.0       0.00              2          1               0   \n",
       "9996    10.0   57369.61              1          1               1   \n",
       "9997     7.0       0.00              1          0               1   \n",
       "9998     3.0   75075.31              2          1               0   \n",
       "9999     NaN  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "0           101348.88       1  \n",
       "1           112542.58       0  \n",
       "2           113931.57       1  \n",
       "3            93826.63       0  \n",
       "4            79084.10       0  \n",
       "...               ...     ...  \n",
       "9995         96270.64       0  \n",
       "9996        101699.77       0  \n",
       "9997         42085.58       1  \n",
       "9998         92888.52       1  \n",
       "9999         38190.78       0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Data Preparation\n",
    "data = pd.read_csv('/datasets/Churn.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "The data was loaded and inspected\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10.0</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>5.0</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "0             1    15634602   Hargrave          619    France  Female   42   \n",
       "1             2    15647311       Hill          608     Spain  Female   41   \n",
       "2             3    15619304       Onio          502    France  Female   42   \n",
       "3             4    15701354       Boni          699    France  Female   39   \n",
       "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
       "...         ...         ...        ...          ...       ...     ...  ...   \n",
       "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
       "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
       "9997       9998    15584532        Liu          709    France  Female   36   \n",
       "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0        2.0       0.00              1          1               1   \n",
       "1        1.0   83807.86              1          0               1   \n",
       "2        8.0  159660.80              3          1               0   \n",
       "3        1.0       0.00              2          0               0   \n",
       "4        2.0  125510.82              1          1               1   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "9995     5.0       0.00              2          1               0   \n",
       "9996    10.0   57369.61              1          1               1   \n",
       "9997     7.0       0.00              1          0               1   \n",
       "9998     3.0   75075.31              2          1               0   \n",
       "9999     5.0  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "0           101348.88       1  \n",
       "1           112542.58       0  \n",
       "2           113931.57       1  \n",
       "3            93826.63       0  \n",
       "4            79084.10       0  \n",
       "...               ...     ...  \n",
       "9995         96270.64       0  \n",
       "9996        101699.77       0  \n",
       "9997         42085.58       1  \n",
       "9998         92888.52       1  \n",
       "9999         38190.78       0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Based on loose correlations above, fill NaNs with the mean of grouped columns with highest degree of correlation.\n",
    "data['Tenure'] = data['Tenure'].fillna(data.groupby(['IsActiveMember', 'HasCrCard', 'NumOfProducts'])['Tenure'].transform('mean').round(0))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "Missing values were dealt with reasonably\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>10.0</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>5.0</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore  Gender  Age  Tenure  \\\n",
       "0             1    15634602   Hargrave          619       0   42     2.0   \n",
       "1             2    15647311       Hill          608       0   41     1.0   \n",
       "2             3    15619304       Onio          502       0   42     8.0   \n",
       "3             4    15701354       Boni          699       0   39     1.0   \n",
       "4             5    15737888   Mitchell          850       0   43     2.0   \n",
       "...         ...         ...        ...          ...     ...  ...     ...   \n",
       "9995       9996    15606229   Obijiaku          771       1   39     5.0   \n",
       "9996       9997    15569892  Johnstone          516       1   35    10.0   \n",
       "9997       9998    15584532        Liu          709       0   36     7.0   \n",
       "9998       9999    15682355  Sabbatini          772       1   42     3.0   \n",
       "9999      10000    15628319     Walker          792       0   28     5.0   \n",
       "\n",
       "        Balance  NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  \\\n",
       "0          0.00              1          1               1        101348.88   \n",
       "1      83807.86              1          0               1        112542.58   \n",
       "2     159660.80              3          1               0        113931.57   \n",
       "3          0.00              2          0               0         93826.63   \n",
       "4     125510.82              1          1               1         79084.10   \n",
       "...         ...            ...        ...             ...              ...   \n",
       "9995       0.00              2          1               0         96270.64   \n",
       "9996   57369.61              1          1               1        101699.77   \n",
       "9997       0.00              1          0               1         42085.58   \n",
       "9998   75075.31              2          1               0         92888.52   \n",
       "9999  130142.79              1          1               0         38190.78   \n",
       "\n",
       "      Exited  Geography_Germany  Geography_Spain  \n",
       "0          1                  0                0  \n",
       "1          0                  0                1  \n",
       "2          1                  0                0  \n",
       "3          0                  0                0  \n",
       "4          0                  0                1  \n",
       "...      ...                ...              ...  \n",
       "9995       0                  0                0  \n",
       "9996       0                  0                0  \n",
       "9997       1                  0                0  \n",
       "9998       1                  1                0  \n",
       "9999       0                  0                0  \n",
       "\n",
       "[10000 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode categorical features\n",
    "label_encoder = LabelEncoder()\n",
    "data['Gender'] = label_encoder.fit_transform(data['Gender'])\n",
    "data = pd.get_dummies(data, columns=['Geography'], drop_first=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "Categorical features were encoded\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>10.0</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>5.0</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0             619       0   42     2.0       0.00              1          1   \n",
       "1             608       0   41     1.0   83807.86              1          0   \n",
       "2             502       0   42     8.0  159660.80              3          1   \n",
       "3             699       0   39     1.0       0.00              2          0   \n",
       "4             850       0   43     2.0  125510.82              1          1   \n",
       "...           ...     ...  ...     ...        ...            ...        ...   \n",
       "9995          771       1   39     5.0       0.00              2          1   \n",
       "9996          516       1   35    10.0   57369.61              1          1   \n",
       "9997          709       0   36     7.0       0.00              1          0   \n",
       "9998          772       1   42     3.0   75075.31              2          1   \n",
       "9999          792       0   28     5.0  130142.79              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Exited  Geography_Germany  \\\n",
       "0                  1        101348.88       1                  0   \n",
       "1                  1        112542.58       0                  0   \n",
       "2                  0        113931.57       1                  0   \n",
       "3                  0         93826.63       0                  0   \n",
       "4                  1         79084.10       0                  0   \n",
       "...              ...              ...     ...                ...   \n",
       "9995               0         96270.64       0                  0   \n",
       "9996               1        101699.77       0                  0   \n",
       "9997               1         42085.58       1                  0   \n",
       "9998               0         92888.52       1                  1   \n",
       "9999               0         38190.78       0                  0   \n",
       "\n",
       "      Geography_Spain  \n",
       "0                   0  \n",
       "1                   1  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   1  \n",
       "...               ...  \n",
       "9995                0  \n",
       "9996                0  \n",
       "9997                0  \n",
       "9998                0  \n",
       "9999                0  \n",
       "\n",
       "[10000 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "Makes sense to drop these columns\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into features (X) and the target variable (y)\n",
    "X = data.drop('Exited', axis=1)\n",
    "y = data['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Balance:\n",
      "0    7963\n",
      "1    2037\n",
      "Name: Exited, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Class Imbalance Examination\n",
    "class_balance = y.value_counts()\n",
    "print(\"Class Balance:\")\n",
    "print(class_balance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "Class imbalance was noted\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier (Validation Set):\n",
      "F1 Score: 0.5764966740576497\n",
      "AUC-ROC Score: 0.853134845255745\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Model Training without Balancing\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Train the model on the training set\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "y_pred_rf_val = rf_classifier.predict(X_val)\n",
    "f1_rf_val = f1_score(y_val, y_pred_rf_val)\n",
    "roc_auc_rf_val = roc_auc_score(y_val, rf_classifier.predict_proba(X_val)[:, 1])\n",
    "\n",
    "print(\"Random Forest Classifier (Validation Set):\")\n",
    "print(f\"F1 Score: {f1_rf_val}\")\n",
    "print(f\"AUC-ROC Score: {roc_auc_rf_val}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<s><b>Reviewer's comment</b>\n",
    "\n",
    "Only the final model should be evaluated on the test set. Before that please use either a separate validation set or cross-validation to evaluate the models. The idea is that the test set is used to get an unbiased estimate of the final model's generalization performance and that is only possible if it is not used to make any decisions about the models.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "  Corrected\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<s><b>Reviewer's comment V2</b>\n",
    "\n",
    "The final model is the single *final* model, the one you select to put in production. It makes no sense to call each model you evaluate a final model :)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment V3</b>\n",
    "\n",
    "Great!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsampled Data:\n",
      "X_train_upsampled shape: (11359, 11)\n",
      "y_train_upsampled shape: (11359,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "def upsample(x_train, y_train, repeat):\n",
    "    x_zeros = x_train[y_train == 0]\n",
    "    x_ones = x_train[y_train == 1]\n",
    "    y_zeros = y_train[y_train == 0]\n",
    "    y_ones = y_train[y_train == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([x_zeros] + [x_ones] * repeat)\n",
    "    target_upsampled = pd.concat([y_zeros] + [y_ones] * repeat)\n",
    "    features_upsampled, target_upsampled = shuffle(features_upsampled, target_upsampled, random_state=12345)\n",
    "\n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "# Upsample the minority class in the training set (e.g., repeat=4)\n",
    "X_train_upsampled, y_train_upsampled = upsample(X_train, y_train, 4)\n",
    "\n",
    "print(\"Upsampled Data:\")\n",
    "print(\"X_train_upsampled shape:\", X_train_upsampled.shape)\n",
    "print(\"y_train_upsampled shape:\", y_train_upsampled.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "Upsampling was applied correctly\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsampled Data:\n",
      "X_train_downsampled shape: (2840, 11)\n",
      "y_train_downsampled shape: (2840,)\n"
     ]
    }
   ],
   "source": [
    "def downsample(x_train, y_train, fraction):\n",
    "    x_zeros = x_train[y_train == 0]\n",
    "    x_ones = x_train[y_train == 1]\n",
    "    y_zeros = y_train[y_train == 0]\n",
    "    y_ones = y_train[y_train == 1]\n",
    "    \n",
    "    features_downsampled = pd.concat(\n",
    "        [x_zeros.sample(frac=fraction, random_state=12345)]\n",
    "        + [x_ones]\n",
    "    )\n",
    "    target_downsampled = pd.concat(\n",
    "        [y_zeros.sample(frac=fraction, random_state=12345)]\n",
    "        + [y_ones]\n",
    "    )\n",
    "\n",
    "    features_downsampled, target_downsampled = shuffle(\n",
    "        features_downsampled, target_downsampled, random_state=12345\n",
    "    )\n",
    "\n",
    "    return features_downsampled, target_downsampled\n",
    "\n",
    "# Downsample the majority class in the training set (e.g., fraction=0.25)\n",
    "X_train_downsampled, y_train_downsampled = downsample(X_train, y_train, 0.25)\n",
    "\n",
    "print(\"Downsampled Data:\")\n",
    "print(\"X_train_downsampled shape:\", X_train_downsampled.shape)\n",
    "print(\"y_train_downsampled shape:\", y_train_downsampled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HEY, I was trying to run the last three codes and it does not seems to work. I am not sure what to do. Could you please let me know how to fix it and what should I add more?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3*3*3*3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "Not sure what you mean by 'does not seem to work'. Did it give you an error? What kind? In any case please direct questions like this to a tutor. The project needs to be fully working without errors to be ready for review :)\n",
    "    \n",
    "My best guess for what you meant is that the cell below takes a long time to run: that is because it needs to train `(3*3*3*3)*5 = 405` models (81 combinations of hyperparameters times 5, as you're doing 5-fold cross-validation). You can try a smaller number of combinations of hyperparameters\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier with Class Weights (Validation Set):\n",
      "F1 Score: 0.5929648241206029\n",
      "AUC-ROC Score: 0.8386713092189195\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and validation sets (use a smaller portion for validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize a RandomForestClassifier with balanced class weights\n",
    "rf_classifier_class_weight = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "\n",
    "# Perform hyperparameter tuning using GridSearchCV\n",
    "grid_search_rf_class_weight = GridSearchCV(rf_classifier_class_weight, param_grid_rf, scoring='f1', cv=3)\n",
    "grid_search_rf_class_weight.fit(X_train, y_train)\n",
    "\n",
    "# Get the best estimator and fit it on the entire training set\n",
    "best_rf_classifier_class_weight = grid_search_rf_class_weight.best_estimator_\n",
    "best_rf_classifier_class_weight.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set and evaluate\n",
    "y_pred_rf_class_weight_val = best_rf_classifier_class_weight.predict(X_val)\n",
    "f1_rf_class_weight_val = f1_score(y_val, y_pred_rf_class_weight_val)\n",
    "roc_auc_rf_class_weight_val = roc_auc_score(y_val, best_rf_classifier_class_weight.predict_proba(X_val)[:, 1])\n",
    "\n",
    "print(\"Random Forest Classifier with Class Weights (Validation Set):\")\n",
    "print(f\"F1 Score: {f1_rf_class_weight_val}\")\n",
    "print(f\"AUC-ROC Score: {roc_auc_rf_class_weight_val}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Classifier without Upsampling (Validation Set):\n",
      "F1 Score: 0.5495495495495495\n",
      "AUC-ROC Score: 0.8307306904037932\n"
     ]
    }
   ],
   "source": [
    "# Initialize a RandomForestClassifier without class weights\n",
    "rf_classifier_upsampled = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform hyperparameter tuning using GridSearchCV\n",
    "grid_search_rf_upsampled = GridSearchCV(rf_classifier_upsampled, param_grid_rf, scoring='f1', cv=3)\n",
    "grid_search_rf_upsampled.fit(X_train, y_train)\n",
    "\n",
    "# Get the best estimator and fit it on the entire training set\n",
    "best_rf_classifier_upsampled = grid_search_rf_upsampled.best_estimator_\n",
    "best_rf_classifier_upsampled.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set and evaluate\n",
    "y_pred_rf_upsampled_val = best_rf_classifier_upsampled.predict(X_val)\n",
    "f1_rf_upsampled_val = f1_score(y_val, y_pred_rf_upsampled_val)\n",
    "roc_auc_rf_upsampled_val = roc_auc_score(y_val, best_rf_classifier_upsampled.predict_proba(X_val)[:, 1])\n",
    "\n",
    "print(\"\\nRandom Forest Classifier without Upsampling (Validation Set):\")\n",
    "print(f\"F1 Score: {f1_rf_upsampled_val}\")\n",
    "print(f\"AUC-ROC Score: {roc_auc_rf_upsampled_val}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<s><b>Reviewer's comment</b>\n",
    "\n",
    "1. Using an upsampled dataset for cross-validation is not appropriate: we can end up with identical examples in train and validation subsets in some folds, inflating the score. For cross-validation we need to apply upsampling in each fold separtely, and only upsample the whole train set just before retraining the final model before evaluating it on the test set (if we choose upsampling as the best method.\n",
    "    \n",
    "2. Please try using class weights and upsampling separately, so that we could compare the effect of the two techniques\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<S><b>Reviewer's comment V2</b>\n",
    "\n",
    "Not sure what the meaning of this loop is:\n",
    "    \n",
    "```python\n",
    "# Perform cross-validation with class weights and without upsampling\n",
    "for train_idx, val_idx in cv.split(X_train, y_train):\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "    # Define and train the Random Forest Classifier with class weights on the fold\n",
    "    rf_classifier_class_weight = GridSearchCV(RandomForestClassifier(random_state=42, class_weight='balanced'),\n",
    "                                              param_grid_rf, scoring='f1', cv=3)\n",
    "    rf_classifier_class_weight.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Store the best estimator for class weights\n",
    "    best_estimators_rf_class_weight.append(rf_classifier_class_weight.best_estimator_)\n",
    "\n",
    "    # Define and train the Random Forest Classifier on the fold (without class weights or upsampling)\n",
    "    rf_classifier_upsampled = GridSearchCV(RandomForestClassifier(random_state=42),\n",
    "                                           param_grid_rf, scoring='f1', cv=3)\n",
    "    rf_classifier_upsampled.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Store the best estimator for upsampling\n",
    "    best_estimators_rf_upsampled.append(rf_classifier_upsampled.best_estimator_)\n",
    "```\n",
    "\n",
    "Remember that GridSearchCV is doing cross-validation under the hood, so you're fitting it on 3 parts of the train set (which is not what cross-validation is: in cross-validation you fit the data using the train fold and evaluate it using the validation fold, then the scores in different folds can be averaged to produce a single number) and putting the best estimators from the grid searches in a list, which is never used for anything: after this loop you just train the model with the default hyperparameters.\n",
    "    \n",
    "Another thing is that the `rf_classifier_upsampled` is not actually trained on upsampled data\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "  Corrected\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment V3</b>\n",
    "\n",
    "For a better fit of upsampling and cross-validation, check out imblearn library. In particular you can use an [imblearn pipeline](https://imbalanced-learn.org/stable/references/generated/imblearn.pipeline.Pipeline.html#imblearn.pipeline.Pipeline) with one of its [oversamplers](https://imbalanced-learn.org/stable/references/over_sampling.html)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code trains two different Random Forest Classifier models: one with class weights and the other without upsampling. Both models are evaluated on the same test set for comparison. This approach ensures that the two techniques are applied separately and their performance can be compared directly on the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with Class Weights (Validation Set):\n",
      "F1 Score: 0.41044776119402987\n",
      "AUC-ROC Score: 0.7030108919985485\n",
      "\n",
      "Logistic Regression with Upsampling (Validation Set):\n",
      "F1 Score: 0.3473861720067454\n",
      "AUC-ROC Score: 0.5809826612537422\n",
      "\n",
      "Logistic Regression Original (No Balancing) (Validation Set):\n",
      "F1 Score: 0.15211267605633802\n",
      "AUC-ROC Score: 0.6664956227887145\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define and train the three logistic regression models\n",
    "logistic_regression_class_weight = LogisticRegression(random_state=42, class_weight='balanced')\n",
    "logistic_regression_upsampled = LogisticRegression(random_state=42)\n",
    "logistic_regression_original = LogisticRegression(random_state=42)  \n",
    "\n",
    "logistic_regression_class_weight.fit(X_train, y_train)\n",
    "logistic_regression_upsampled.fit(X_train_upsampled, y_train_upsampled)\n",
    "logistic_regression_original.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set and calculate F1 scores and AUC-ROC scores\n",
    "y_pred_logistic_class_weight = logistic_regression_class_weight.predict(X_temp)\n",
    "f1_logistic_class_weight = f1_score(y_temp, y_pred_logistic_class_weight)\n",
    "roc_auc_logistic_class_weight = roc_auc_score(y_temp, logistic_regression_class_weight.predict_proba(X_temp)[:, 1])\n",
    "\n",
    "y_pred_logistic_upsampled = logistic_regression_upsampled.predict(X_temp)\n",
    "f1_logistic_upsampled = f1_score(y_temp, y_pred_logistic_upsampled)\n",
    "roc_auc_logistic_upsampled = roc_auc_score(y_temp, logistic_regression_upsampled.predict_proba(X_temp)[:, 1])\n",
    "\n",
    "y_pred_logistic_original = logistic_regression_original.predict(X_temp)\n",
    "f1_logistic_original = f1_score(y_temp, y_pred_logistic_original)\n",
    "roc_auc_logistic_original = roc_auc_score(y_temp, logistic_regression_original.predict_proba(X_temp)[:, 1])\n",
    "\n",
    "# Print the F1 scores and AUC-ROC scores for each model on the validation set\n",
    "print(\"Logistic Regression with Class Weights (Validation Set):\")\n",
    "print(f\"F1 Score: {f1_logistic_class_weight}\")\n",
    "print(f\"AUC-ROC Score: {roc_auc_logistic_class_weight}\")\n",
    "\n",
    "print(\"\\nLogistic Regression with Upsampling (Validation Set):\")\n",
    "print(f\"F1 Score: {f1_logistic_upsampled}\")\n",
    "print(f\"AUC-ROC Score: {roc_auc_logistic_upsampled}\")\n",
    "\n",
    "print(\"\\nLogistic Regression Original (No Balancing) (Validation Set):\")\n",
    "print(f\"F1 Score: {f1_logistic_original}\")\n",
    "print(f\"AUC-ROC Score: {roc_auc_logistic_original}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier with Class Weights (Test Set):\n",
      "F1 Score: 0.6184012066365008\n",
      "AUC-ROC Score: 0.8624055555555556\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the final model on the test set\n",
    "y_pred_rf_class_weight_test = best_rf_classifier_class_weight.predict(X_test)\n",
    "f1_rf_class_weight_test = f1_score(y_test, y_pred_rf_class_weight_test)\n",
    "roc_auc_rf_class_weight_test = roc_auc_score(y_test, best_rf_classifier_class_weight.predict_proba(X_test)[:, 1])\n",
    "\n",
    "print(\"Random Forest Classifier with Class Weights (Test Set):\")\n",
    "print(f\"F1 Score: {f1_rf_class_weight_test}\")\n",
    "print(f\"AUC-ROC Score: {roc_auc_rf_class_weight_test}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<S><b>Reviewer's comment</b>\n",
    "\n",
    "You say\n",
    "    \n",
    "> Compare F1 scores and AUC-ROC values of the models on the validation set\n",
    "    \n",
    "but the models are evaluated on the test set...\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "  Corrected\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<s>\n",
    "    <b>Reviewer's comment V2</b>\n",
    "\n",
    "As you already split the data into train, validation and test sets earlier, there's no need to do it again:\n",
    "    \n",
    "```python\n",
    "# Split the data into training (80%) and validation (20%) sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "```\n",
    "    \n",
    "Also it seems you're a bit confused about the purpose of these sets. Let's recap:\n",
    "    \n",
    "1. The train set is used to train the model\n",
    "2. The validation set is used to evaluate different models (or variations of the same model with different hyperparameters), compare their results and select the best model. The validation set may be replaced with cross-validation on the train set.\n",
    "3. The test used is used to evaluate a single final model (not each model)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment V3</b>\n",
    "\n",
    "All looks good now! Well done!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion: Customer Churn Prediction for Beta Bank\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we set out to address Beta Bank's pressing issue of customer churn by developing a machine learning model capable of predicting which customers are likely to leave the bank. By achieving this, Beta Bank can proactively take measures to retain existing customers and reduce the need for acquiring new ones. The project unfolded through several key stages:\n",
    "\n",
    "Data Preparation: We began by downloading and preprocessing the dataset, ensuring that it was ready for model training. This involved handling missing values, encoding categorical features, and scaling numeric attributes.\n",
    "\n",
    "Class Imbalance Analysis: We explored the class distribution in the dataset, and it became evident that there was a significant class imbalance with more customers who stayed with the bank than those who left.\n",
    "\n",
    "Model Training without Balancing: We initially trained machine learning models without addressing the class imbalance. This provided us with baseline performance metrics to assess the severity of the problem.\n",
    "\n",
    "Improving Model Quality: To combat class imbalance, we explored various techniques, including upsampling the minority class and assigning class weights. Through hyperparameter tuning and grid search, we optimized our models for better predictive accuracy.\n",
    "\n",
    "Model Training and Validation: We trained multiple models, including Random Forest and Logistic Regression, comparing their performance using F1 scores and AUC-ROC values on validation sets.\n",
    "\n",
    "Selecting the Best Model: Based on our evaluation, we selected the model with the highest F1 score as the best-performing model. This model demonstrated a strong ability to identify customers at risk of churning.\n",
    "\n",
    "Final Testing: We assessed the chosen model on a test dataset to obtain its final performance metrics. The model's F1 score and AUC-ROC score on the test set provided a robust evaluation of its predictive capabilities.\n",
    "\n",
    "By successfully completing this project, we have equipped Beta Bank with a powerful tool to predict customer churn accurately. This predictive capability will allow Beta Bank to take proactive actions, such as personalized retention strategies and improved customer service, to retain valued customers. Ultimately, this approach will not only enhance customer satisfaction but also contribute to cost savings and the long-term success of Beta Bank in a competitive financial landscape.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment V3</b>\n",
    "\n",
    "Nice summary!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
